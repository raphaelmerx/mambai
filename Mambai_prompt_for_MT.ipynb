{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99FcPOEGHhei"
      },
      "source": [
        "# Prompt tuning for translating English > Mambai\n",
        "\n",
        "Translate an English sentence to Mambai by:\n",
        "\n",
        "1. Find closest sentences using LASER\n",
        "2. Find dictionary entries for words in sentence\n",
        "3. Construct prompt, with a mix of example sentences and dict entries\n",
        "\n",
        "TODO:\n",
        "\n",
        "- Clean up Mambai corpus\n",
        "  - Some dict entries missing as it relies on font weight, which is not always OCRed correctly\n",
        "    - others need to be separated (e.g. \"sit; live\")\n",
        "  - Some sentences poorly aligned\n",
        "- Get similar sentences based on syntactic similarity, instead of `get_sentences_starting_with_same_words`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3FCNpgjQfmJ"
      },
      "source": [
        "### Get Mambai corpus, split between sentences and dict entries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yJi5_ROHxbx",
        "outputId": "0f1aba58-0eb2-4c01-fafc-6163cdfb497e"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import random\n",
        "\n",
        "with open(\"mambai_parallel_eng_mgm.csv\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    data = list(reader)\n",
        "\n",
        "print(f\"Total of {len(data)} rows in the dataset.\")\n",
        "\n",
        "train_data = [r for r in data if r[\"split\"] == \"train\"]\n",
        "\n",
        "print(f\"Total of {len(train_data)} rows in the training set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1jl2YHnKOyb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"eng_mgm.json\") as f:\n",
        "    dict_entries = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# experiment tracking in https://docs.google.com/spreadsheets/d/1wP0tDiPqmS8UWNiyY4oSAZn3Mzw2Z4FTZZOQ5lf-NHQ/edit#gid=0\n",
        "\n",
        "# config = {\n",
        "#     \"model\": \"gpt-4\",\n",
        "#     \"train_rows\": len(train_data),\n",
        "#     \"retrieval_sentences\": {\"tfidf\": 5},\n",
        "#     \"retrieval_dict\": True,\n",
        "#     \"bleu\": 12.6,\n",
        "#     \"chrf\": 32.4,\n",
        "# }\n",
        "\n",
        "config = {\n",
        "    \"model\": \"gpt-4\",\n",
        "    \"train_rows\": len(train_data),\n",
        "    \"retrieval_sentences\": {\"tfidf\": 10},\n",
        "    \"retrieval_dict\": False,\n",
        "    \"bleu\": 12.6,\n",
        "    \"chrf\": 32.4,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "\n",
        "def find_top_k_tfidf(sentence, eng_sentences, top_k=5):\n",
        "    # Ensure the given sentence is included in the list of sentences to compare\n",
        "    documents = [sentence] + eng_sentences\n",
        "\n",
        "    # Initialize the TF-IDF Vectorizer and transform the documents into TF-IDF vectors\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Compute the cosine similarity between the first document (the given sentence)\n",
        "    # and all other documents\n",
        "    cosine_similarities = linear_kernel(tfidf_matrix[0:1], tfidf_matrix).flatten()\n",
        "\n",
        "    # Find the indices of the top k similarity scores (excluding the first document itself)\n",
        "    # We add 1 to skip the first document which is the input sentence itself\n",
        "    top_k_indices = cosine_similarities[1:].argsort()[-top_k:][::-1] + 1\n",
        "\n",
        "    return [train_data[index - 1] for index in top_k_indices]\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "eng_sentences = [row[\"English (eng)\"] for row in train_data]\n",
        "input_sentence = \"We will be sitting there having coffee\"\n",
        "\n",
        "num_to_retrieve = config[\"retrieval_sentences\"][\"tfidf\"]\n",
        "top_tfidf = find_top_k_tfidf(input_sentence, eng_sentences, num_to_retrieve)\n",
        "\n",
        "print(f\"Top {num_to_retrieve} similar sentences for '{input_sentence}'\")\n",
        "for sentence in top_tfidf:\n",
        "    print(sentence[\"English (eng)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpbX6yQ9QjWi"
      },
      "source": [
        "### Get LASER encoder, encode English sentences from Mambai corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWujkAkbH9jL",
        "outputId": "b997d471-6fc3-47dd-8863-f9fb909f3962"
      },
      "outputs": [],
      "source": [
        "from laser_encoders import LaserEncoderPipeline\n",
        "\n",
        "encoder = LaserEncoderPipeline(lang=\"eng_Latn\")\n",
        "\n",
        "embeddings = encoder.encode_sentences([row[\"English (eng)\"] for row in train_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dvdmc61QziP"
      },
      "source": [
        "### Construct prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrrZMS9uKYUY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def find_top_k_semantic_laser(input, top_k=5):\n",
        "    embedded_input = encoder.encode_sentences([input])\n",
        "    closest_indices = cosine_similarity(embedded_input, embeddings)[0].argsort()[\n",
        "        -top_k:\n",
        "    ][::-1]\n",
        "    return [train_data[i] for i in closest_indices]\n",
        "\n",
        "\n",
        "def get_sentences_starting_with_same_words(input):\n",
        "    input_words = input.split()\n",
        "    first_two_words = \" \".join(input_words[:2])\n",
        "    for row in train_data:\n",
        "        if row[\"English (eng)\"].startswith(first_two_words):\n",
        "            yield row\n",
        "\n",
        "\n",
        "def get_relevant_dict_entries(sent):\n",
        "    doc = nlp(sent)\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    for lemma in lemmas:\n",
        "        for row in dict_entries:\n",
        "            if row[\"entry\"] == lemma:\n",
        "                yield row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAlNs-5CKY3w"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"You are a translator for the Mambai language, originally from Timor-Leste.\n",
        "\n",
        "# Example sentences\n",
        "{sentences_str}\n",
        "\n",
        "{dict_section}English: {input}\n",
        "Mambai:\"\"\"\n",
        "\n",
        "\n",
        "def format_prompt(sentences_str, dict_str, input):\n",
        "    dict_section = f\"# Dictionary entries\\n{dict_str}\\n\\n\" if dict_str else \"\"\n",
        "    return prompt_template.format(\n",
        "        sentences_str=sentences_str, dict_section=dict_section, input=input\n",
        "    )\n",
        "\n",
        "\n",
        "def get_sentences_str(rows):\n",
        "    out = \"\"\n",
        "    for row in rows:\n",
        "        out += f\"English: {row['English (eng)']}\\n\"\n",
        "        out += f\"Mambai: {row['Mambai (mgm)']}\\n\"\n",
        "        out += \"\\n\"\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_dict_str(dict_entries):\n",
        "    out = \"\"\n",
        "    for row in dict_entries:\n",
        "        out += f\"English: {row['entry']}\\n\"\n",
        "        out += f\"Mambai: {row['definition']}\\n\"\n",
        "        out += \"\\n\"\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_prompt(input):\n",
        "    sentences = []\n",
        "    if \"tfidf\" in config[\"retrieval_sentences\"]:\n",
        "        tfidf_count = config[\"retrieval_sentences\"][\"tfidf\"]\n",
        "        sentences.extend(find_top_k_tfidf(input, eng_sentences, tfidf_count))\n",
        "    if \"semantic_laser\" in config[\"retrieval_sentences\"]:\n",
        "        semantic_count = config[\"retrieval_sentences\"][\"semantic_laser\"]\n",
        "        sentences.extend(find_top_k_semantic_laser(input, semantic_count))\n",
        "    if config[\"retrieval_dict\"]:\n",
        "        dict_entries = list(get_relevant_dict_entries(input))\n",
        "    else:\n",
        "        dict_entries = []\n",
        "    return format_prompt(\n",
        "        sentences_str=get_sentences_str(sentences),\n",
        "        dict_str=get_dict_str(dict_entries),\n",
        "        input=input,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(get_prompt(\"We will be sitting there having coffee\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "async def get_gpt4_translation(sentence):\n",
        "    chat_completion = await client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": get_prompt(sentence)}],\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "    )\n",
        "    translation = chat_completion.choices[0].message.content\n",
        "    # if \"Mambai: \" in translation, keep the part of the string after it\n",
        "    translation = translation.split(\"Mambai: \")[-1]\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_data = [r for r in data if r[\"split\"] == \"dev\"]\n",
        "print(f\"Total of {len(dev_data)} rows in the validation set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "\n",
        "async def process_batch(sentences):\n",
        "    tasks = [get_gpt4_translation(sentence) for sentence in sentences]\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "async def translate_data(dev_data):\n",
        "    batch_size = 10\n",
        "    for i in range(0, len(dev_data), batch_size):\n",
        "        print(f\"Processing batch {i+1} to {i+batch_size}\")\n",
        "        batch = dev_data[i : i + batch_size]\n",
        "        translations = await process_batch([row[\"English (eng)\"] for row in batch])\n",
        "        # for each row, add the translation under key 'mgm_translation'\n",
        "        for row, translation in zip(batch, translations):\n",
        "            row[\"mgm_translation\"] = translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to run asyncio tasks from Jupyter Notebook\n",
        "async def run(coroutine):\n",
        "    try:\n",
        "        # Attempt to get the running event loop\n",
        "        loop = asyncio.get_running_loop()\n",
        "    except RuntimeError:  # If no running event loop\n",
        "        loop = asyncio.new_event_loop()  # Create a new loop\n",
        "        asyncio.set_event_loop(loop)\n",
        "    return await coroutine\n",
        "\n",
        "\n",
        "await run(translate_data(dev_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU score: 0.13551247392372268\n",
            "ChrF score: 38.21808456442234\n",
            "Chrf++ score: 37.240239918245415\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "predictions = [row[\"mgm_translation\"] for row in dev_data]\n",
        "references = [[row[\"Mambai (mgm)\"]] for row in dev_data]\n",
        "\n",
        "# Calculate metrics\n",
        "bleu_results = bleu.compute(predictions=predictions, references=references)\n",
        "chrf_results = chrf.compute(predictions=predictions, references=references)\n",
        "chrfpp_results = chrf.compute(\n",
        "    predictions=predictions, references=references, word_order=2\n",
        ")\n",
        "\n",
        "print(f\"BLEU score: {bleu_results['bleu']}\")\n",
        "print(f\"ChrF score: {chrf_results['score']}\")\n",
        "print(f\"Chrf++ score: {chrfpp_results['score']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
