{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99FcPOEGHhei"
      },
      "source": [
        "# Prompt tuning for translating English > Mambai\n",
        "\n",
        "Translate an English sentence to Mambai by:\n",
        "\n",
        "1. Find closest sentences using TF-IDF / semantic embeddings / both\n",
        "2. Find dictionary entries for words in sentence\n",
        "3. Construct prompt, with a mix of example sentences and dict entries\n",
        "\n",
        "TODO:\n",
        "\n",
        "- Clean up Mambai corpus\n",
        "  - Some dict entries missing as it relies on font weight, which is not always OCRed correctly\n",
        "    - others need to be separated (e.g. \"sit; live\")\n",
        "  - Some sentences poorly aligned\n",
        "- Get similar sentences based on syntactic similarity, instead of `get_sentences_starting_with_same_words`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3FCNpgjQfmJ"
      },
      "source": [
        "### Get Mambai corpus, split between sentences and dict entries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yJi5_ROHxbx",
        "outputId": "0f1aba58-0eb2-4c01-fafc-6163cdfb497e"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "import random\n",
        "\n",
        "with open(\"test_leo.json\") as f:\n",
        "    test_data = json.load(f)\n",
        "print(f\"For use in the test set, we have {len(test_data)} sentences.\")\n",
        "\n",
        "with open(\"mambai_parallel_eng_mgm.csv\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    data = list(reader)\n",
        "\n",
        "\n",
        "print(f\"Total of {len(data)} rows in the dataset.\")\n",
        "\n",
        "train_data = [r for r in data if r[\"split\"] == \"train\"]\n",
        "\n",
        "print(f\"Total of {len(train_data)} rows in the training set.\")\n",
        "\n",
        "\n",
        "# average number of words in in the data set\n",
        "\n",
        "avg_words_mgm = sum(len(r[\"Mambai (mgm)\"].split()) for r in data) / len(data)\n",
        "avg_words_eng = sum(len(r[\"English (eng)\"].split()) for r in data) / len(data)\n",
        "\n",
        "print(f\"Average number of Mambai words per sentence: {avg_words_mgm:.2f}\")\n",
        "print(f\"Average number of English words per sentence: {avg_words_eng:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# only keep examples from the Mambau Language Manual\n",
        "\n",
        "print(f\"Total of {len(data)} rows in the dataset.\")\n",
        "data = [d for d in data if d[\"source\"].startswith(\"Mambai Language Manual\")]\n",
        "print(\n",
        "    f\"Total of {len(data)} rows in the dataset after filtering for the Mambai Language Manual.\"\n",
        ")\n",
        "\n",
        "\n",
        "# how many are from the dev + test split?\n",
        "dev_or_test = [d for d in data if d[\"split\"] in [\"dev\", \"test\"]]\n",
        "print(f\"Total of {len(dev_or_test)} rows in the dev or test split.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TMP: use all data as train_data\n",
        "\n",
        "train_data = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from unidecode import unidecode\n",
        "\n",
        "keys = [\"Mambai (mgm)\", \"English (eng)\"]\n",
        "\n",
        "\n",
        "def make_lowercase_and_remove_accents(s):\n",
        "    return unidecode(s[0].lower() + s[1:])\n",
        "\n",
        "\n",
        "def make_lowercase_and_remove_accents_for_keys(row, keys):\n",
        "    for key in keys:\n",
        "        row[key] = make_lowercase_and_remove_accents(row[key])\n",
        "\n",
        "\n",
        "for row in train_data:\n",
        "    make_lowercase_and_remove_accents_for_keys(row, keys)\n",
        "for row in test_data:\n",
        "    make_lowercase_and_remove_accents_for_keys(row, keys)\n",
        "\n",
        "random.sample(train_data, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1jl2YHnKOyb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"eng_mgm.json\") as f:\n",
        "    dict_entries = json.load(f)\n",
        "\n",
        "print(f\"Total of {len(dict_entries)} entries in the English > Mambai dictionary.\")\n",
        "\n",
        "random.sample(dict_entries, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# experiment tracking in https://docs.google.com/spreadsheets/d/1wP0tDiPqmS8UWNiyY4oSAZn3Mzw2Z4FTZZOQ5lf-NHQ/edit#gid=0\n",
        "\n",
        "config = {\n",
        "    \"baseline\": False,\n",
        "    \"model\": \"gpt-4\",\n",
        "    \"train_rows\": len(train_data),\n",
        "    \"retrieval_sentences\": {\"tfidf\": 5, \"semantic_laser\": 5},\n",
        "    \"retrieval_dict\": True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "\n",
        "def find_top_k_tfidf(sentence, eng_sentences, top_k=5):\n",
        "    # Ensure the given sentence is included in the list of sentences to compare\n",
        "    documents = [sentence] + eng_sentences\n",
        "\n",
        "    # Initialize the TF-IDF Vectorizer and transform the documents into TF-IDF vectors\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "    # Compute the cosine similarity between the first document (the given sentence)\n",
        "    # and all other documents\n",
        "    cosine_similarities = linear_kernel(tfidf_matrix[0:1], tfidf_matrix).flatten()\n",
        "\n",
        "    # Find the indices of the top k similarity scores (excluding the first document itself)\n",
        "    # We add 1 to skip the first document which is the input sentence itself\n",
        "    top_k_indices = cosine_similarities[1:].argsort()[-top_k:][::-1] + 1\n",
        "\n",
        "    return [train_data[index - 1] for index in top_k_indices]\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "eng_sentences = [row[\"English (eng)\"] for row in train_data]\n",
        "input_sentence = \"we will be sitting there having coffee\"\n",
        "\n",
        "num_to_retrieve = config[\"retrieval_sentences\"][\"tfidf\"]\n",
        "top_tfidf = find_top_k_tfidf(input_sentence, eng_sentences, num_to_retrieve)\n",
        "\n",
        "print(f\"Top {num_to_retrieve} similar sentences for '{input_sentence}'\")\n",
        "for sentence in top_tfidf:\n",
        "    print(sentence[\"English (eng)\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpbX6yQ9QjWi"
      },
      "source": [
        "### Get LASER encoder, encode English sentences from Mambai corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWujkAkbH9jL",
        "outputId": "b997d471-6fc3-47dd-8863-f9fb909f3962"
      },
      "outputs": [],
      "source": [
        "from laser_encoders import LaserEncoderPipeline\n",
        "\n",
        "encoder = LaserEncoderPipeline(lang=\"eng_Latn\")\n",
        "\n",
        "embeddings = encoder.encode_sentences([row[\"English (eng)\"] for row in train_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dvdmc61QziP"
      },
      "source": [
        "### Construct prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrrZMS9uKYUY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def find_top_k_semantic_laser(input, top_k=5):\n",
        "    embedded_input = encoder.encode_sentences([input])\n",
        "    closest_indices = cosine_similarity(embedded_input, embeddings)[0].argsort()[\n",
        "        -top_k:\n",
        "    ][::-1]\n",
        "    return [train_data[i] for i in closest_indices]\n",
        "\n",
        "\n",
        "def get_sentences_starting_with_same_words(input):\n",
        "    input_words = input.split()\n",
        "    first_two_words = \" \".join(input_words[:2])\n",
        "    for row in train_data:\n",
        "        if row[\"English (eng)\"].startswith(first_two_words):\n",
        "            yield row\n",
        "\n",
        "\n",
        "def get_relevant_dict_entries(sent):\n",
        "    doc = nlp(sent)\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    for lemma in lemmas:\n",
        "        for row in dict_entries:\n",
        "            if row[\"entry\"] == lemma:\n",
        "                yield row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAlNs-5CKY3w"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"You are a translator for the Mambai language, originally from Timor-Leste.\n",
        "\n",
        "{sentences_section}{dict_section}Please provide the translation for the following sentence. Do not provide any explanations or text apart from the translation.\n",
        "\n",
        "English: {input}\n",
        "Mambai:\"\"\"\n",
        "\n",
        "baseline_prompt = \"\"\"You are a translator for the Mambai language, originally from Timor-Leste.\n",
        "\n",
        "English: Whom have you told about his imprisonment?\n",
        "Mambai: It tou It kaben ni problema lao sen?\n",
        "\n",
        "Please provide the translation for the following sentence. Do not provide any explanations or text apart from the translation.\n",
        "\n",
        "English: {input}\n",
        "Mambai:\"\"\"\n",
        "\n",
        "\n",
        "def format_prompt(sentences_str, dict_str, input):\n",
        "    sentences_section = (\n",
        "        f\"### Example sentences ###\\n{sentences_str}\\n\\n\" if sentences_str else \"\"\n",
        "    )\n",
        "    dict_section = f\"### Dictionary entries ###\\n{dict_str}\\n\\n\" if dict_str else \"\"\n",
        "    return prompt_template.format(\n",
        "        sentences_section=sentences_section, dict_section=dict_section, input=input\n",
        "    )\n",
        "\n",
        "\n",
        "def get_sentences_str(rows):\n",
        "    out = \"\"\n",
        "    for row in rows:\n",
        "        out += f\"English: {row['English (eng)']}\\n\"\n",
        "        out += f\"Mambai: {row['Mambai (mgm)']}\\n\"\n",
        "        out += \"\\n\"\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_dict_str(dict_entries):\n",
        "    out = \"\"\n",
        "    for row in dict_entries:\n",
        "        out += f\"English: {row['entry']}\\n\"\n",
        "        out += f\"Mambai: {row['definition']}\\n\"\n",
        "        out += \"\\n\"\n",
        "    return out\n",
        "\n",
        "\n",
        "def get_prompt(input):\n",
        "    sentences = []\n",
        "    if \"baseline\" in config and config[\"baseline\"]:\n",
        "        return baseline_prompt.format(input=input)\n",
        "    if \"tfidf\" in config[\"retrieval_sentences\"]:\n",
        "        tfidf_count = config[\"retrieval_sentences\"][\"tfidf\"]\n",
        "        sentences.extend(find_top_k_tfidf(input, eng_sentences, tfidf_count))\n",
        "    if \"semantic_laser\" in config[\"retrieval_sentences\"]:\n",
        "        semantic_count = config[\"retrieval_sentences\"][\"semantic_laser\"]\n",
        "        sentences.extend(find_top_k_semantic_laser(input, semantic_count))\n",
        "    if config[\"retrieval_dict\"]:\n",
        "        dict_entries = list(get_relevant_dict_entries(input))\n",
        "    else:\n",
        "        dict_entries = []\n",
        "    return format_prompt(\n",
        "        sentences_str=get_sentences_str(sentences),\n",
        "        dict_str=get_dict_str(dict_entries),\n",
        "        input=input,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(get_prompt(\"we will be sitting there having coffee\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AsyncOpenAI\n",
        "import replicate\n",
        "import re\n",
        "\n",
        "# nltk: sent\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "openai_client = AsyncOpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "\n",
        "# assumes REPLICATE_API_TOKEN is set in env\n",
        "def get_replicate_translation(\n",
        "    sentence, model=\"mistralai/mixtral-8x7b-instruct-v0.1\"\n",
        ") -> str:\n",
        "    output = replicate.run(\n",
        "        model,\n",
        "        input={\n",
        "            \"prompt\": get_prompt(sentence),\n",
        "        },\n",
        "    )\n",
        "    output = \"\".join(output).strip()\n",
        "    sentences = sent_tokenize(output)\n",
        "    if len(sentences) == 0:\n",
        "        return \"\"\n",
        "    # only keep the first sentence in output, as Mixtral keeps giving explanations despite the prompt asking it not to\n",
        "    output = sentences[0]\n",
        "    # if part of the output has \"(note: ...)\", keep the part of the string before it\n",
        "    output = re.sub(r\"\\([nN]ote:.*\\)\", \"\", output).strip()\n",
        "    # if \"Mambai: \" in translation, keep the part of the string after it\n",
        "    output = output.split(\"Mambai: \")[-1]\n",
        "    return output\n",
        "\n",
        "\n",
        "async def get_gpt4_translation(sentence) -> str:\n",
        "    chat_completion = await openai_client.chat.completions.create(\n",
        "        messages=[{\"role\": \"user\", \"content\": get_prompt(sentence)}],\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "    )\n",
        "    translation = chat_completion.choices[0].message.content\n",
        "    # if \"Mambai: \" in translation, keep the part of the string after it\n",
        "    translation = translation.split(\"Mambai: \")[-1]\n",
        "    return translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_data = [r for r in data if r[\"split\"] == \"dev\"]\n",
        "print(f\"Total of {len(dev_data)} rows in the validation set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "\n",
        "async def process_batch_gpt4(sentences):\n",
        "    tasks = [get_gpt4_translation(sentence) for sentence in sentences]\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "async def process_batch_replicate(sentences, model):\n",
        "    loop = asyncio.get_running_loop()\n",
        "    # run_in_executor to run synchronous code in a separate thread\n",
        "    tasks = [\n",
        "        loop.run_in_executor(None, get_replicate_translation, sentence, model)\n",
        "        for sentence in sentences\n",
        "    ]\n",
        "    return await asyncio.gather(*tasks)\n",
        "\n",
        "\n",
        "async def translate_data(dev_data):\n",
        "    batch_size = 10\n",
        "    for i in range(0, len(dev_data), batch_size):\n",
        "        print(f\"Processing batch {i+1} to {i+batch_size}\")\n",
        "        batch = dev_data[i : i + batch_size]\n",
        "        if all(\"mgm_translation\" in row for row in batch):\n",
        "            print(\"All batch elements already have the 'mgm_translation' key, skipping\")\n",
        "            continue\n",
        "        if config[\"model\"].startswith(\"gpt-4\"):\n",
        "            translations = await process_batch_gpt4(\n",
        "                [row[\"English (eng)\"] for row in batch]\n",
        "            )\n",
        "        elif config[\"model\"] == \"mixtral\":\n",
        "            translations = await process_batch_replicate(\n",
        "                [row[\"English (eng)\"] for row in batch],\n",
        "                \"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
        "            )\n",
        "        elif config[\"model\"] == \"llama\":\n",
        "            translations = await process_batch_replicate(\n",
        "                [row[\"English (eng)\"] for row in batch],\n",
        "                \"meta/llama-2-70b-chat\",\n",
        "            )\n",
        "        # for each row, add the translation under key 'mgm_translation'\n",
        "        for row, translation in zip(batch, translations):\n",
        "            row[\"mgm_translation\"] = make_lowercase_and_remove_accents(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to run asyncio tasks from Jupyter Notebook\n",
        "async def run(coroutine):\n",
        "    try:\n",
        "        # Attempt to get the running event loop\n",
        "        loop = asyncio.get_running_loop()\n",
        "    except RuntimeError:  # If no running event loop\n",
        "        loop = asyncio.new_event_loop()  # Create a new loop\n",
        "        asyncio.set_event_loop(loop)\n",
        "    return await coroutine\n",
        "\n",
        "\n",
        "await run(translate_data(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "predictions = [row[\"mgm_translation\"] for row in test_data]\n",
        "references = [[row[\"Mambai (mgm)\"]] for row in test_data]\n",
        "\n",
        "# Calculate metrics\n",
        "bleu_results = bleu.compute(predictions=predictions, references=references)\n",
        "chrf_results = chrf.compute(predictions=predictions, references=references)\n",
        "chrfpp_results = chrf.compute(\n",
        "    predictions=predictions, references=references, word_order=2\n",
        ")\n",
        "\n",
        "print(f\"BLEU score: {bleu_results['bleu']}\")\n",
        "print(f\"ChrF score: {chrf_results['score']}\")\n",
        "print(f\"Chrf++ score: {chrfpp_results['score']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# valid set\n",
        "\n",
        "valid_data = [row for row in data if row[\"split\"] == \"test\"]\n",
        "print(f\"Total of {len(valid_data)} rows in the validation set.\")\n",
        "\n",
        "random.sample(valid_data, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
